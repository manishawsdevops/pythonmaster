# Pyspark is a tool that is used to interact with SPARK using Python as an API.

# https://www.tutorialspoint.com/pyspark

# Pyspark has below terminilogy to understand.

# To learn Python We can use the Jupyter Notebooks.

# Fundamental Concept in Spark - RDD.
# RDD Stands for Resilient Distributed Dataset.

# RDD Operations:
# Transform
# Apply

# Creating an RDD

# words = sc.parellelize(['a','b','c'])

# The two types of variables supported by Apache Spark.
# Broadcast
# Accumulator

# Spark files contains two spark methods
